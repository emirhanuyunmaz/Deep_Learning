{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04697eef-c8bc-497a-933c-029fef6d40e5",
   "metadata": {},
   "source": [
    "# Otokodlayıcılar (Autoencoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab021875-6cd6-4621-96c6-9778d2ce479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms , datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aeb635-39cf-44f3-9961-57100ec20ade",
   "metadata": {},
   "source": [
    "**Problem Tanımı:** Veri boyut küçültme \\\n",
    "Veri : FashionMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e1b015a-7da2-4088-8d82-f0e3facefaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 26.4M/26.4M [00:20<00:00, 1.27MB/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 29.5k/29.5k [00:00<00:00, 414kB/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 4.42M/4.42M [00:03<00:00, 1.15MB/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 5.15k/5.15k [00:00<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()]) # Görüntüleri tensore çevir [0-1] aralığında\n",
    "\n",
    "# Eğitim ve test veri setini indir\n",
    "train_dataset = datasets.FashionMNIST(root = \"FashionMNIST_data\" , train = True , transform = transform , download = True )\n",
    "test_dataset = datasets.FashionMNIST(root = \"FashionMNIST_data\" , train = False , transform = transform , download = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3709064d-1fdf-4620-9930-5f1fc96cf40c",
   "metadata": {},
   "source": [
    "**Eğitim ve test veri seti yükleyicilerini oluşturma**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1971b4d1-ac85-448f-b930-89c659691a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 \n",
    "train_loader = DataLoader(train_dataset , batch_size = batch_size , shuffle = True)\n",
    "test_loader = DataLoader(test_dataset , batch_size = batch_size , shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa52c0c-6bde-440b-aafb-74109b565f11",
   "metadata": {},
   "source": [
    "**Auto Encoder Geliştirme**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fff6460-7e2e-4bd1-bd31-d2f30d5d1d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Flatten(), # 28 x 28 -> 784 (1D) Vektör\n",
    "            nn.Linear(28 * 28 , 256), # Tam bağlı katman 784 -> 256\n",
    "            nn.ReLU(), # Aktivasyon fonk.\n",
    "            nn.Linear(256 , 64), # Tam bağlı katman 256 -> 64\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(64,256), # Tam bağlı katman 64 -> 256\n",
    "            nn.ReLU(), # Aktivasyon Fonk.\n",
    "            nn.Linear(256 , 28 * 28), # Tam bağlı katman\n",
    "            nn.Sigmoid(), # Sigmoid 0-1 aralığında tutmak için kullanılır\n",
    "            nn.Unflatten(1 , (1 , 28 , 28)) # Tek boyutlu çıktıyı tekrar 28 x 28 yapar\n",
    "        \n",
    "        )\n",
    "    def forward(self,x):\n",
    "        encoded = self.encoder(x) # Giriş verisini kodlar\n",
    "        decoded = self.decoder(encoded) # Kodlanmış veriyi tekrar görüntüye dönüştürür \n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3c2f2e-8c96-42fb-85d5-11471d9b0d81",
   "metadata": {},
   "source": [
    "**Callback : Early Stopping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa6afb16-1874-4a06-8ce6-39096f40d43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    \n",
    "    def __init__(self, patience = 3 , min_delta = 0.001 ):\n",
    "        # Kaç epoch boyunca gelişme olmazsa durduracağını belirleyen parametre\n",
    "        self.patience = patience\n",
    "\n",
    "        # Kayıptaki min. iyileşme sayısı\n",
    "        self.min_delta = min_delta\n",
    "\n",
    "        # En iyi kayıp değerleri\n",
    "        self.best_loss = None\n",
    "    \n",
    "        # Sabit kalan epoch sayısı (counter)\n",
    "        self.counter = 0\n",
    "    \n",
    "    def __call__(self,loss):\n",
    "        # Gelişme var\n",
    "        if self.best_loss is None or loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = loss\n",
    "            self.counter = 0 \n",
    "        # Gelişme yok\n",
    "        else:\n",
    "            self.counter += 1\n",
    "\n",
    "        # Sabit kalan epoch sayısı patience i aşarsa -> Durdur\n",
    "        if self.counter >= self.patience :\n",
    "            return True # Training'i durdur\n",
    "            \n",
    "        return False\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfef1360-a8ac-4197-affb-f5453c3d5fad",
   "metadata": {},
   "source": [
    "**Modelin Eğitimi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d0ac77d-924a-416c-9fb6-ce572b950ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "learning_rate = 1e-3 \n",
    "\n",
    "# Model , Loss , Optimizer Tanımlama\n",
    "model = AutoEncoder() # Modeli tanımlama\n",
    "criterion = nn.MSELoss() # Kayıp Fonksiyonu -> MSE : ortalama kare hata\n",
    "optimizer = optim.Adam(model.parameters(),lr = learning_rate) # Optimizer\n",
    "early_stopping = EarlyStopping(patience = 5 , min_delta = 0.001) # Erken durdurma\n",
    "\n",
    "# Eğitim Fonk.\n",
    "\n",
    "def training(model,train_loader , optimizer , criterion , early_stopping , epochs):\n",
    "    model.train() # Modeli Eğitim moduna al\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0 #Epoch başına toplam kayıt\n",
    "\n",
    "        for inputs , _ in train_loader:\n",
    "            optimizer.zero_grad() # Gradyanları sıfırla\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs , inputs) # Gerçek ve tahmini veriler arasındaki kayıp\n",
    "            loss.backward() # Gradyanları hesaplama\n",
    "            optimizer.step() # Ağırlıkları güncelle\n",
    "            total_loss += loss.item() # Her bir epoch için toplam loss değeri\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader) # Epoch başına ortalama kayıp hesaplama\n",
    "        print(f\"Epoch :{epoch+1}/{epochs} - Loss : {avg_loss:5f} \")\n",
    "\n",
    "        # Early Stopping\n",
    "        if early_stopping(avg_loss):\n",
    "            print(f\"Early Stopping at epoch {epoch+1} \")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29ecafda-f7a6-4f08-afb2-23f6b1db9475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :1/50 - Loss : 0.033305 \n",
      "Epoch :2/50 - Loss : 0.017248 \n",
      "Epoch :3/50 - Loss : 0.014544 \n",
      "Epoch :4/50 - Loss : 0.013141 \n",
      "Epoch :5/50 - Loss : 0.012193 \n",
      "Epoch :6/50 - Loss : 0.011461 \n",
      "Epoch :7/50 - Loss : 0.010888 \n",
      "Epoch :8/50 - Loss : 0.010485 \n",
      "Epoch :9/50 - Loss : 0.010068 \n",
      "Epoch :10/50 - Loss : 0.009789 \n",
      "Epoch :11/50 - Loss : 0.009479 \n",
      "Epoch :12/50 - Loss : 0.009245 \n",
      "Epoch :13/50 - Loss : 0.008994 \n",
      "Epoch :14/50 - Loss : 0.008819 \n",
      "Epoch :15/50 - Loss : 0.008643 \n",
      "Epoch :16/50 - Loss : 0.008519 \n",
      "Epoch :17/50 - Loss : 0.008390 \n",
      "Epoch :18/50 - Loss : 0.008274 \n",
      "Early Stopping at epoch 18 \n"
     ]
    }
   ],
   "source": [
    "training(model , train_loader , optimizer , criterion , early_stopping , epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfe2d77-d446-4295-8737-2e6501042784",
   "metadata": {},
   "source": [
    "**Modelin Test Edilmesi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13c70f52-8683-4596-a25d-b27a77f5fd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ssim(img1, img2, sigma=1.5):\n",
    "    \"\"\"\n",
    "    iki goruntu arasindaki benzerligi hesaplar\n",
    "    \"\"\"\n",
    "    C1 = (0.01*255)**2 # ssim sabitlerinden bir tanesi\n",
    "    C2 = (0.03*255)**2 # diger bir sabit\n",
    "    \n",
    "    img1 = img1.astype(np.float64)\n",
    "    img2 = img2.astype(np.float64)\n",
    "    \n",
    "    # goruntulerin ortalamalari\n",
    "    mu1 = gaussian_filter(img1, sigma)\n",
    "    mu2 = gaussian_filter(img2, sigma)\n",
    "    \n",
    "    # \n",
    "    mu1_sq = mu1**2 # ilk goruntunun ortalamasinin karesini aldik\n",
    "    mu2_sq = mu2**2 \n",
    "    mu1_mu2 = mu1 * mu2\n",
    "    \n",
    "    sigma1_sq = gaussian_filter(img1 **2, sigma) - mu1_sq # varyans hesabi\n",
    "    sigma2_sq = gaussian_filter(img2 **2, sigma) - mu2_sq\n",
    "    sigma12 = gaussian_filter(img1*img2, sigma) - mu1_mu2 # kovaryans hesabi\n",
    "    \n",
    "    # ssim haritasi hesaplama\n",
    "    ssim_map = ((2*mu1_mu2 + C1) * (2 * sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n",
    "    \n",
    "    return ssim_map.mean()\n",
    "\n",
    "def evaluate(model , test_loader , n_images = 10):\n",
    "    model.eval() # Modelin değerlendirme moduna al\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            inputs , _ = batch\n",
    "            outputs = model(inputs) # Modelin çıktılarını üretiyoruz\n",
    "            break\n",
    "    inputs = inputs.numpy() # Numpy array'e çevir\n",
    "    outputs = outputs.numpy() # Numpy array'e çevir\n",
    "\n",
    "    fig , axes = plt.subplots(2 , n_images , figsize = (n_images , 3)) # Görselleştirme için sublot\n",
    "    ssim_scores = []\n",
    "\n",
    "    for i in range(n_images) :\n",
    "        img1 = np.squeeze(inputs[i]) # Orijinal görüntü\n",
    "        img2 = np.squeeze(outputs[i]) # Decoded edilen görüntü\n",
    "\n",
    "        ssim_score = compute_ssim(img1, img2) # ssim skoru yani benzerlik hesapla\n",
    "        ssim_scores.append(ssim_score) # ssim skorunu listeye ekle\n",
    "        \n",
    "        axes[0,i].imshow(img1, cmap = \"gray\")\n",
    "        axes[0,i].axis(\"off\")\n",
    "        axes[1,i].imshow(img2, cmap = \"gray\")\n",
    "        axes[1,i].axis(\"off\")\n",
    "        \n",
    "    axes[0,0].set_title(\"Original\")\n",
    "    axes[1,0].set_title(\"Decoded image\")\n",
    "    plt.show()\n",
    "    \n",
    "    avg_ssim = np.mean(ssim_scores)\n",
    "    print(f\"Average SSIM: {avg_ssim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3f7d190-c5c4-43af-892c-6947fbe83aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate(model, test_loader, n_images = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6deb58d-eeaa-4c0b-866d-ddfeb63cf8da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
